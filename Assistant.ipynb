{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import wikipedia as wk\n",
    "import webbrowser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import pyttsx3\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something:\n",
      "['what', 'is', 'the', 'opposite', 'of', 'beautiful']\n",
      "ugly\n"
     ]
    }
   ],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate',120)\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say Something:\")\n",
    "    audio = r.listen(source)\n",
    "    text = r.recognize_google(audio)\n",
    "    t=text.split(\" \")\n",
    "print(t)\n",
    "if 'name' in t:\n",
    "    engine.say(\"My name is Ananay Gupta\")\n",
    "    engine.runAndWait()\n",
    "elif 'age' in t:\n",
    "    engine.say(\"My age is 20 years\")\n",
    "    engine.runAndWait()\n",
    "elif 'about' in t:\n",
    "    i=t.index('about')\n",
    "    print(wk.summary(t[i+1:]))\n",
    "    engine.say(wk.summary(t[i+1:]))\n",
    "    engine.runAndWait()\n",
    "elif 'play' in t:\n",
    "    i=t.index('play')\n",
    "    name=t[i+1:]\n",
    "    n=\"\"\n",
    "    for x in name:\n",
    "        n=n+x+\" \"\n",
    "    print(n)\n",
    "    url='https://www.youtube.com/results?search_query='+n\n",
    "    r=requests.get(url)\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup=BeautifulSoup(r.text,'html.parser')\n",
    "    soup.prettify\n",
    "\n",
    "    l=[]\n",
    "    for link in soup.find_all('a'):\n",
    "        if(link['href'][:6]=='/watch'):\n",
    "            l.append(\"https://www.youtube.com/\"+link['href'])\n",
    "    webbrowser.open(l[0])\n",
    "elif 'temperature' in t:\n",
    "    i=t.index('temperature')\n",
    "    x=\"\"+t[i+2]\n",
    "    r=requests.get(f'https://api.openweathermap.org/data/2.5/weather?q={x}&appid=94946c72f63e40971c24d47aa1f64fa2')\n",
    "    d=json.loads(r.text)\n",
    "    df=pd.DataFrame(d['main'],index=[1])\n",
    "    df[['temp','feels_like','temp_min','temp_max']]=df[['temp','feels_like','temp_min','temp_max']]-273.15\n",
    "    df['description']=d['weather'][0]['description']\n",
    "    t=df['temp']\n",
    "    t=round(t.values[0],1)\n",
    "    engine.say(f\"Temperature in {x} is {t} degree celsius\")\n",
    "    engine.runAndWait()\n",
    "elif 'news' in t:\n",
    "    r=requests.get('https://newsapi.org/v2/top-headlines?q=india&apiKey=c6eb1d3676144c0f8af0a52251950ac7')\n",
    "    d=json.loads(r.text)\n",
    "    df=pd.DataFrame(d['articles'])\n",
    "    d1=df['description'].values\n",
    "    for x in d1:\n",
    "        print(x)\n",
    "        engine.say(x)\n",
    "        time.sleep(0.2)\n",
    "        engine.runAndWait()\n",
    "elif 'cases' in t:\n",
    "    r=requests.get('https://api.covid19india.org/raw_data1.json')\n",
    "    d=json.loads(r.text)\n",
    "    df1=pd.DataFrame(d['raw_data'])\n",
    "    r=requests.get('https://api.covid19india.org/raw_data2.json')\n",
    "    d=json.loads(r.text)\n",
    "    df2=pd.DataFrame(d['raw_data'])\n",
    "    r=requests.get('https://api.covid19india.org/raw_data3.json')\n",
    "    d=json.loads(r.text)\n",
    "    df3=pd.DataFrame(d['raw_data'])\n",
    "    del df1['backupnotes']\n",
    "    del df2['backupnotes']\n",
    "    df=df1.append(df3)\n",
    "    df=df.append(df2)\n",
    "    r=requests.get('https://api.covid19india.org/raw_data4.json')\n",
    "    d=json.loads(r.text)\n",
    "    df4=pd.DataFrame(d['raw_data'])\n",
    "    df=df.append(df4)\n",
    "    df['numcases'] = df['numcases'].apply(lambda x: '1' if x =='' else x)\n",
    "    df['numcases']=pd.to_numeric(df['numcases'])\n",
    "    df=df.drop(['source1','source2','source3','patientnumber','notes','estimatedonsetdate','entryid'],axis=1)\n",
    "    g=df.dateannounced.str.split('/',expand=True).iloc[:,0:3]\n",
    "    g.columns=['day','month','year']\n",
    "    df=pd.concat([df,g],axis=1)\n",
    "    d=df[df['currentstatus']==\"Hospitalized\"]\n",
    "    i=t.index('cases')\n",
    "    state=t[i+2]\n",
    "    if 'India' in t:\n",
    "        s=d.numcases.sum()\n",
    "    else:\n",
    "        d1=d[(d['detectedstate']==t[i+2])]\n",
    "        s=d1.numcases.sum()\n",
    "    engine.say(f\"There are  total {s} cases in {state}\")\n",
    "    engine.runAndWait()\n",
    "elif 'meaning' in t:\n",
    "    i=t.index('meaning')\n",
    "    word=t[i+2]\n",
    "    SynArr=wordnet.synsets(word)\n",
    "    syn=SynArr[0]\n",
    "    print(syn.definition())\n",
    "    engine.say(f\"Meaning of {word} is {syn.definition()}\")\n",
    "    engine.runAndWait()\n",
    "elif 'opposite' in t:\n",
    "    i=t.index('opposite')\n",
    "    word=t[i+2]\n",
    "    SynArr=wordnet.synsets(word)\n",
    "    print(SynArr[0].lemmas()[0].antonyms()[0].name())\n",
    "    engine.say(f\"Opposite of {word} is {SynArr[0].lemmas()[0].antonyms()[0].name()}\")\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
